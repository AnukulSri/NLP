{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bag of Words\n",
    "\n",
    "- It us used for text representation\n",
    "- it represent text data as a collection or bag of words\n",
    "- It simplifies text into numerical form for machine learning algorithm to process\n",
    "\n",
    "### Stpes for this model to work\n",
    " - Tokenization\n",
    " - vocabulary creation\n",
    " - counting word occurence\n",
    " - vector representation\n",
    "\n",
    "#### all this things can be done by scikit learn library. In sklearn there is a module **CountVectorize** with the help of it we can convert text into vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "para = \"\"\"The world is a vast expanse of incredible diversity, where cultures, traditions, and people intertwine to form a rich tapestry of humanity.\n",
    " From the bustling streets of New York City, where skyscrapers pierce the sky, to the serene landscapes of the Amazon rainforest, \n",
    " where vibrant wildlife thrives in harmony, every corner of this planet holds its own unique wonders. Traveling through the cobbled \n",
    " streets of ancient European cities, one can feel the weight of history in every stone, while the tranquil temples of Asia exude a sense of \n",
    " spiritual tranquility. Across continents, languages dance in the air, each carrying its own melody and stories passed down through generations. \n",
    " In the heart of Africa, the rhythmic beats of drums echo the soul of a vibrant continent, while the icy landscapes of Antarctica stand in stark \n",
    " contrast, reminding us of the planet's extremes. Nature's marvels, from the majestic peaks of the Himalayas to the crystal-clear waters of the\n",
    "Great Barrier Reef, leave us awestruck by their beauty and grandeur. Humanity's accomplishments, from scientific breakthroughs to artistic \n",
    "masterpieces, shape the world and propel us into the future. As we navigate the complexities of the modern age, the interconnectedness of our \n",
    "global community becomes increasingly apparent. The internet serves as a digital bridge, connecting minds and ideas across continents in an instant. \n",
    "Yet, amidst our technological advancements, we face challenges that demand collective action - environmental crises, social inequalities, \n",
    "and geopolitical tensions. However, hope glimmers on the horizon, fueled by the determination of individuals and organizations working tirelessly\n",
    " for positive change. In the quiet moments of reflection, we find solace in the simple joys of life - a shared meal with loved ones, the laughter of children\n",
    " playing, and the beauty of a sunset painting the sky in hues of orange and gold. Our world, with all its complexities and contradictions, \n",
    " remains a place of infinite possibilities, where the human spirit perseveres, inspired by the promise of a better tomorrow.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = nltk.sent_tokenize(para)\n",
    "lem = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "corpus =[] # this is to store text after cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(sentence)):\n",
    "    review = re.sub('[^a-zA-Z]',' ',sentence[i]) # this will remove everything except characters\n",
    "    # print(review)\n",
    "    review = review.lower()\n",
    "    review=review.split()\n",
    "    review = [lem.lemmatize(word) for word in review if not word in set(stopwords.words('english'))]\n",
    "    review = ' '.join(review)\n",
    "    corpus.append(review)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# creating bag of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(max_features=1500)\n",
    "x= cv.fit_transform(corpus).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 1, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 1],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 1, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- now we can apply machine learning on it."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
